{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358ad76f",
   "metadata": {},
   "source": [
    "__Завгородняя Марина Игоревна Группа MADE-DS-22__ \n",
    "\n",
    "Второе домашнее задание по курсу \"Продвинутое машинное обучение\":\n",
    "\n",
    "- MCMC-сэмплирование и «пляшущие человечки»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f210007",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38786a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e867df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class TextEncryptor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.corpora = None\n",
    "        self.freq_dict = None\n",
    "        self.random_mapping = None\n",
    "\n",
    "    def fit(self, corpora):\n",
    "        \"\"\"\n",
    "\n",
    "        :param corpora: частотный словарь корпуса известного языка\n",
    "        \"\"\"\n",
    "        self.corpora = corpora\n",
    "        self.freq_dict = self._get_freq_dict(self.corpora)\n",
    "        self.random_mapping = self._create_random_mapping(self.freq_dict)\n",
    "\n",
    "    def decrypt_frequency_method(self, unknown_text: str):\n",
    "        \"\"\"Расшифровывает текст с помощью частотного метода.\n",
    "        unknown_text: текст для расшифровки\"\"\"\n",
    "        freq_dict_unknown_text = self._get_freq_dict(unknown_text)\n",
    "        mapping_for_decrypt = self._create_mapping_by_freq_dicts(\n",
    "            self.freq_dict, freq_dict_unknown_text\n",
    "        )\n",
    "        return self._map_text(unknown_text, mapping_for_decrypt)\n",
    "\n",
    "    def encrypt_random(self, text: str):\n",
    "        return self._map_text(text, self.random_mapping)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_freq_dict(text) -> dict:\n",
    "        \"\"\" Возвращает dict частотности символов {'x': n} в тексте text \"\"\"\n",
    "        counter = Counter(text)\n",
    "        sorted_dict = {\n",
    "            k: v for k, v in sorted(dict(counter).items(), key=lambda item: -item[1])\n",
    "        }\n",
    "        return sorted_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_random_mapping(freq_dict: dict):\n",
    "        \"\"\"Возвращает два маппинга: прямой и обратный, для шифрования текстов случайной перестановкой\"\"\"\n",
    "        alfabet = list(freq_dict.keys())\n",
    "        alfabet_copy = alfabet.copy()\n",
    "        random.shuffle(alfabet_copy)\n",
    "        mapping = dict(zip(alfabet, alfabet_copy))\n",
    "        return mapping\n",
    "\n",
    "    @staticmethod\n",
    "    def _map_text(text: str, mapping: dict):\n",
    "        \"\"\"Заменяет символы в тексте согласно мапингу\"\"\"\n",
    "        f = lambda x: mapping.get(x, \"%\")\n",
    "        result = \"\".join(list(map(f, text)))\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_mapping_by_freq_dicts(freq_dict_1: dict, freq_dict_2: dict):\n",
    "        \"\"\"Создает маппинг для расшифровки текста на основе частотных dicts.\n",
    "        freq_dict_1: частотный dict для корпуса текста на известном языке (отсортирован по убыванию частоты)\n",
    "        freq_dict_2: частотный dict для неизвестного текста (отсортирован по убыванию частоты)\n",
    "        \"\"\"\n",
    "        alfabet_1 = list(freq_dict_1.keys())\n",
    "        alfabet_2 = list(freq_dict_2.keys())\n",
    "        min_len = min(len(alfabet_1), len(alfabet_2))\n",
    "        alfabet_1 = alfabet_1[:min_len]\n",
    "        alfabet_2 = alfabet_2[:min_len]\n",
    "        return dict(zip(alfabet_2, alfabet_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1570226a",
   "metadata": {},
   "source": [
    "## Read and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92deb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_clean_text(path: str):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    text = \" \".join(lines)\n",
    "    clean_text = re.sub(\"\\W+\", \" \", text).lower()\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab992cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_and_clean_text(\"../corpora/WarAndPeace.txt\")\n",
    "text_en = read_and_clean_text(\"../corpora/WarAndPeaceEng.txt\")\n",
    "text_anna = read_and_clean_text(\"../corpora/AnnaKarenina.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2bbf2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'вронский понял тоже как мог быть силен серпуховской своею несомненною способностью обдумывать понимать вещи своим умом и даром слова так редко встречающимся в той среде в которой он жил и как ни совестно это было ему ему было завидно все таки мне недостает для этого одной главной вещи отвечал он недостает желания власти это было но прошло извини меня это неправда улыбаясь сказал серпуховской нет правда правда теперь чтоб быть искренним прибавил вронский да правда теперь это другое дело но это теперь будет не всегда может быть отвечал вронский ты говоришь может быть продолжал серпуховской как будто угадав его мысли а я тебе говорю наверное и для этого я хотел тебя видеть ты поступил так как должно было это я понимаю но персеверировать ты не должен я только прошу у тебя carte blanche 128 я не покровительствую тебе хотя отчего же мне и не покровительствовать тебе ты столько раз мне покровительствовал надеюсь что наша дружба стоит выше этого да'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тестовые куски из Анны Карениной\n",
    "\n",
    "test_sample = text_anna[650_106:651_060]\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539b3721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'она не слышала половины его слов она испытывала страх к нему и думала о том правда ли то что вронский не убился о нем ли говорили что он цел а лошадь сломала спину она только притворно насмешливо улыбнулась когда он кончил и ничего не отвечала потому что не слыхала того что он говорил алексей александрович начал говорить смело но когда он ясно понял то о чем он говорит страх который она испытывала сообщился ему он увидел эту улыбку и странное заблуждение нашло на него она улыбается над моими подозрениями да она скажет сейчас то что говорила мне тот раз что нет оснований моим подозрениям что это смешно теперь когда над ним висело открытие всего он ничего так не желал как того чтобы она так же как прежде насмешливо ответила ему что его подозрения смешны и не имеют основания так страшно было то что он знал что теперь он был готов поверить всему но выражение лица ее испуганного и мрачного теперь не обещало даже обмана может быть я ошибаюсь сказал он в таком случае я прошу'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample2 = text_anna[450_076:451_058]\n",
    "test_sample2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f9ae59",
   "metadata": {},
   "source": [
    "## Baseline frequency method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655135fb",
   "metadata": {},
   "source": [
    "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "* подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "* возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "* расшифруйте их таким частотным методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "503a5a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестовые зашифрованные перестановкой куски:\n",
      "7о5îéтбjqв5îgüqй5nцqтâтqd5êqwшй4qéбüцîqéцовet57éт5jqé75цэqîцé5dîцîî5эqéв5é5wî5éй,\n",
      "5îâqîцqéüшvâüâqв5ü57бîшqцê5qéü57q5îâqбéвшйш7âüâqéйоâtqтqîцdeqбqûedâüâq5qй5dqвоâ7\n"
     ]
    }
   ],
   "source": [
    "# Вспомогательный класс для шифровки/расшифровки текстов частотным методом\n",
    "text_encryptor = TextEncryptor()\n",
    "\n",
    "# \"Обучаем\" на частотах символов русской версии Войны и Мир\n",
    "text_encryptor.fit(text)\n",
    "\n",
    "# Шифруем тестовые куски текста из Анны Карениной случайной перестановкой\n",
    "mapped_test_sample = text_encryptor.encrypt_random(test_sample)\n",
    "mapped_test_sample2 = text_encryptor.encrypt_random(test_sample2)\n",
    "print(f\"Тестовые зашифрованные перестановкой куски:\\n{mapped_test_sample[:80]},\\n{mapped_test_sample2[:80]}\")\n",
    "\n",
    "# Расшифруем тестовые куски частотным методом\n",
    "decrypted_test_sample = text_encryptor.decrypt_frequency_method(mapped_test_sample)\n",
    "decrypted_test_sample2 = text_encryptor.decrypt_frequency_method(mapped_test_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "877faa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'нвотсдлб мотыр еоча дид яоз уьеп слрат савмгхонсдоб сноаж тасоятаттож смосоутосепж оукгяьниеп мотляиеп нацл сноля гяоя л кивоя срони еид вакдо нсевашижцлясы н еоб свака н доеовоб от члр л дид тл сонасето йео уьро аяг аяг уьро юинлкто нса еидл ята такосеиае кры йеозо октоб зринтоб нацл оенашир от такосеиае чаритлы нрисел йео уьро то мвоeро люнлтл яаты йео тамвинки грьуиысп сдиюир савмгхонсдоб тае мвинки мвинки еамавп шеоу уьеп лсдваттля мвлуинлр нвотсдлб ки мвинки еамавп йео квгзоа каро то йео еамавп угкае та нсазки яочае уьеп оенашир нвотсдлб еь зоновлeп яочае уьеп мвокорчир савмгхонсдоб дид угкео гзикин азо яьсрл и ы еауа зоновж тинавтоа л кры йеозо ы хоеар еауы нлкаеп еь мосегмлр еид дид корчто уьро йео ы мотляиж то мавсанавлвониеп еь та корчат ы еорпдо мвоeг г еауы nsari uostnэi щlф ы та модвонлеарпсенгж еауа хоеы оешазо ча ята л та модвонлеарпсенониеп еауа еь сеорпдо вию ята модвонлеарпсенонир тикажсп шео тиeи квгчуи сеоле ньeа йеозо ки'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypted_test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d5e9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'оеа еи лтябата готоксея иуо лток оеа слгяняката лнвах д еирп с ьпрата о нор гвакьа тс но мно квоелдсш еи пыстлз о еир тс уоковстс мно ое eит а тобаьч лтората лгсеп оеа нотчдо гвснковео еалрибтско птяыепталч доуьа ое доемст с есмиуо еи онкимата гонорп мно еи лтяхата ноуо мно ое уоковст атидлиш атидлаеьвоксм еамат уоковснч лрито ео доуьа ое злео гоезт но о мир ое уоковсн лнвах доновяш оеа слгяняката лооыюстлз ирп ое пксьит цнп птяыдп с лнваееои жаытпйьиеси еабто еа еиуо оеа птяыаинлз еаь росрс гоьожвиесзрс ьа оеа лдайин лишмал но мно уоковста реи нон важ мно еин олеокаесш роср гоьожвиесзр мно цно лрибео нигивч доуьа еаь еср кслито ондвянси клиуо ое есмиуо над еи йитат дад ноуо мноыя оеа над йи дад гвийьи еалрибтско онкинста ирп мно иуо гоьожвиесз лрибея с еи сриnн олеокаесз над лнвабео ыято но мно ое жеат мно нигивч ое ыят уонок гокивснч клирп ео кявайиеси тсeа ии слгпуаееоуо с рвамеоуо нигивч еи оыиюато ьайи оыраеа ройин ыянч з обсыаnлч лдажат ое к надор лтпмаи з гвобп'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decrypted_test_sample2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01dd282",
   "metadata": {},
   "source": [
    "* Расшифровка частотным методом с использованием посимвольной частоты получилась не очень."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c00607a",
   "metadata": {},
   "source": [
    "## Bigram frequency method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8d5a6",
   "metadata": {},
   "source": [
    "Сделаем следующий логический шаг для улучшения:\n",
    "* подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "* проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae033cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I ',\n",
       " ' r',\n",
       " 're',\n",
       " 'ea',\n",
       " 'al',\n",
       " 'll',\n",
       " 'ly',\n",
       " 'y ',\n",
       " ' l',\n",
       " 'li',\n",
       " 'ik',\n",
       " 'ke',\n",
       " 'e ',\n",
       " ' p',\n",
       " 'py',\n",
       " 'yt',\n",
       " 'th',\n",
       " 'ho',\n",
       " 'on',\n",
       " 'n,',\n",
       " ', ',\n",
       " ' i',\n",
       " 'it',\n",
       " \"t'\",\n",
       " \"'s\",\n",
       " 's ',\n",
       " ' p',\n",
       " 'pr',\n",
       " 're',\n",
       " 'et',\n",
       " 'tt',\n",
       " 'ty',\n",
       " 'y ',\n",
       " ' a',\n",
       " 'aw',\n",
       " 'we',\n",
       " 'es',\n",
       " 'so',\n",
       " 'om',\n",
       " 'me',\n",
       " 'e.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "string = \"I really like python, it's pretty awesome.\"\n",
    "string_bigrams = bigrams(string)\n",
    "[b[0]+b[1] for b in string_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae5b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_ml_hw3",
   "language": "python",
   "name": "adv_ml_hw3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
